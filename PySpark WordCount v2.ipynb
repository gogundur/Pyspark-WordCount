{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order for Python to find the Spark, download the findspark library and start it with findspark.init() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to work with RDDs, we need to create a SparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Since we write local [*] in the master, it will use all cores in our machine. If we said local [4] it will work with 4 cores. It can work in local / yarn / mesos and kubernetes mode.\n",
    "\n",
    "## getOrCreate is used to create a SparkSession if not present.\n",
    "\n",
    "\n",
    "## If we do not import SparkConf, we will need to assign executor.memory and driver.memory values to do these operations. In such cases you can determine the configuration values as in the example below.\n",
    "\n",
    "    conf=SparkConf()\\\n",
    "            .setMaster(local[*])\\\n",
    "            .setappName(\"WordCount\")\\\n",
    "            .setExecutorEnv(\"spark.executor.memory\",\"4g\")\\\n",
    "            .setExecutorEnv(\"spark.driver.memory\",\"4g\")\n",
    "      spark=SparkSession.builder\\\n",
    "            .config(conf=conf)\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"WordCount\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data - RomeoJuliet Txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veri_dosyasi=\"/Users/gulcanogundur/Downloads/romeojuliet.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_rdd=sc.textFile(veri_dosyasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"                    WILLIAM SHAKESPEARE'S\",\n",
       " '',\n",
       " '                       ROMEO & JULIET',\n",
       " '',\n",
       " '   ADAPTED FOR THE SCREEN BY CRAIG PEARCE AND BAZ LUHRMANN',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '                                       FINAL SHOOTING SCRIPT',\n",
       " '',\n",
       " '                                             October 6, 1995',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'EXT.  HIGHWAY.  AFTERNOON.',\n",
       " '',\n",
       " 'A ribbon of freeway stretching into a blue and pink late',\n",
       " 'afternoon sky. A huge dark sedan, windows tinted gold,',\n",
       " 'headlights blazing, powers directly for us.',\n",
       " '',\n",
       " 'CUT TO: A heavy, low-slung, pickup truck traveling toward',\n",
       " 'the sedan.',\n",
       " '',\n",
       " 'WIDE SHOT: Sky, freeway, the cars closing.',\n",
       " '',\n",
       " 'TIGHT ON: The sedan.',\n",
       " '',\n",
       " 'TIGHT ON: The pickup.',\n",
       " '',\n",
       " 'Like thunderous, jousting opponents, the cars pass in a',\n",
       " 'deafening cacophony of noise.',\n",
       " '',\n",
       " 'INT.  TRUCK.  AFTERNOON.',\n",
       " '',\n",
       " 'TIGHT ON: The fat face of GREGORY, yelling at the',\n",
       " 'disappearing sedan.',\n",
       " '',\n",
       " '                         GREGORY',\n",
       " '            A dog of the house of Capulet moves',\n",
       " '            me!',\n",
       " '',\n",
       " 'He and the pimply-faced front-seat passenger, SAMPSON,',\n",
       " 'explode with laughter.',\n",
       " '',\n",
       " 'The red-haired driver BENVOLIO, keeps his eyes on the road.',\n",
       " '',\n",
       " 'EXT.  EXIT RAMP.  AFTERNOON.',\n",
       " '',\n",
       " 'The truck spirals down an exit ramp and screeches into busy',\n",
       " 'driveway of a large gas station.',\n",
       " '',\n",
       " 'EXT.  GAS STATION.  AFTERNOON.',\n",
       " '',\n",
       " 'Attendants immediately run to the truck.  Two clean',\n",
       " 'windshields and duco, the third fills the gas tank.',\n",
       " '',\n",
       " 'INT.  TRUCK.  AFTERNOON.',\n",
       " '',\n",
       " 'Gregory in the back seat is boasting outrageously.',\n",
       " '',\n",
       " '                         GREGORY',\n",
       " '            A dog of that house shall move me',\n",
       " '            to stand.  I will take the wall of',\n",
       " '            any man or maid of Capulets.',\n",
       " '',\n",
       " 'Sampson, sarcastically.',\n",
       " '',\n",
       " '                         SAMPSON',\n",
       " '            That shows thee a weak slave.  For',\n",
       " '            the weakest goes to the wall.',\n",
       " '',\n",
       " '                         GREGORY',\n",
       " \"            'Tis true; and therefore women,\",\n",
       " '            being the weaker vessels, are ever',\n",
       " '            thrust to the wall.  Therefore, I']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_rdd.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6247"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation and Transform All Words to Lowercase.\n",
    "\n",
    "### To exclude punctuation values and convert all words to lowercase, we wrote a function like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_clean_str(x):\n",
    "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
    "  lowercased_str = x.lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, '')\n",
    "  return lowercased_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_rdd = shakespeare_rdd.map(lower_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '                    william shakespeares',\n",
       " '',\n",
       " '                       romeo  juliet',\n",
       " '',\n",
       " '   adapted for the screen by craig pearce and baz luhrmann',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '                                       final shooting script',\n",
       " '',\n",
       " '                                             october 6 1995',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ext  highway  afternoon']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_rdd.take(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use split function to separate the words in all lines ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_rdd=shakespeare_rdd.flatMap(lambda satir: satir.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We do a filtering below to exclude whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_rdd = shakespeare_rdd.filter(lambda x:x!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['william', 'shakespeares', 'romeo', 'juliet']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_rdd.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count how many times each word occurs.\n",
    "### To make this calculation we can apply the “reduceByKey” transformation on (key,val) pair RDD. We need to first convert “shakespeare_rdd” to (key,val) pair RDD.\n",
    "\n",
    "### In this new (key,val) pair RDD (shakespeare_count), key is the word and val is 1 for each word in RDD (1 represents the number for the each word in “shakespeare_rdd”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_count=shakespeare_rdd.map(lambda  word:(word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('william', 1), ('shakespeares', 1), ('romeo', 1), ('juliet', 1)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_count.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ReduceByKey to find frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_count_RBK=shakespeare_count.reduceByKey(lambda x,y:(x+y)).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1995', 1),\n",
       " ('21', 1),\n",
       " ('6', 1),\n",
       " ('60', 2),\n",
       " ('9mm', 2),\n",
       " ('a', 563),\n",
       " ('abandoned', 1),\n",
       " ('able', 1),\n",
       " ('about', 3),\n",
       " ('above', 12),\n",
       " ('abra', 24),\n",
       " ('abras', 3),\n",
       " ('abroad', 1),\n",
       " ('abrupt', 1),\n",
       " ('abruptly', 5),\n",
       " ('absolved', 1),\n",
       " ('abuse', 2),\n",
       " ('abuses', 1),\n",
       " ('accidentally', 1),\n",
       " ('accompanied', 1),\n",
       " ('according', 1),\n",
       " ('accusation', 1),\n",
       " ('accustomed', 2),\n",
       " ('ache', 1),\n",
       " ('aches', 1),\n",
       " ('achingly', 2),\n",
       " ('acoustic', 1),\n",
       " ('across', 24),\n",
       " ('actually', 1),\n",
       " ('adagio', 1),\n",
       " ('adapted', 1),\n",
       " ('address', 1),\n",
       " ('addressed', 1),\n",
       " ('addresses', 1),\n",
       " ('adept', 1),\n",
       " ('adieu', 4),\n",
       " ('adjacent', 1),\n",
       " ('adjoining', 1),\n",
       " ('adjust', 1),\n",
       " ('admired', 1)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_count_RBK.take(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to sort the most frequent words in descending order. As the first step, we switch (key,val) pairs as (val,key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_count_RBK=shakespeare_count_RBK.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '1995'), (1, '21'), (1, '6'), (2, '60'), (2, '9mm')]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_count_RBK.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We see that the most common word is \"the\". However, these values are words that we call stopwords which brings value to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1372, 'the'),\n",
       " (563, 'a'),\n",
       " (506, 'to'),\n",
       " (469, 'of'),\n",
       " (464, 'romeo'),\n",
       " (461, 'and'),\n",
       " (258, 'in'),\n",
       " (251, 'juliet'),\n",
       " (246, 'is'),\n",
       " (224, 'i')]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_count_RBK.sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To exclude stopwords words, we download the nltk library and get the list of English stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gulcanogundur/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords =stopwords.words('english')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When we exclude stopwords values, we see that the word \"romeo\" is the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shakespeare_count_RBK = shakespeare_count_RBK.filter(lambda x: x[1] not in stopwords).sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(464, 'romeo'),\n",
       " (251, 'juliet'),\n",
       " (143, 'mercutio'),\n",
       " (133, 'capulet'),\n",
       " (114, 'thou'),\n",
       " (111, 'benvolio'),\n",
       " (111, 'night'),\n",
       " (98, 'father'),\n",
       " (97, 'ext'),\n",
       " (96, 'close'),\n",
       " (96, 'nurse'),\n",
       " (92, 'cont'),\n",
       " (88, 'int'),\n",
       " (87, 'cut'),\n",
       " (84, 'car'),\n",
       " (82, 'love'),\n",
       " (81, 'laurence'),\n",
       " (79, 'tybalt'),\n",
       " (71, 'gloria'),\n",
       " (66, 'day')]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_count_RBK.sortByKey(False).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
